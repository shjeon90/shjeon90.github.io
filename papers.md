## About this page...
```
This page is written for summarizing the remarkable research papers I read. 
Currently, the papers are not organized and formatted.
Somday, I'll reorganize them, I think...
Keep updating...
```

## Remarkable research papers on Deep Learning
- K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick, “Momentum Contrast for Unsupervised Visual Representation Learning,” in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2020, doi: 10.1109/CVPR42600.2020.00975.
- M. Chen et al., “Generative Pretraining from Pixels,” in ICML 2020, 2020.
- J. Devlin, M. W. Chang, K. Lee, and K. Toutanova, “BERT: Pre-training of deep bidirectional transformers for language understanding,” in NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference, 2019.
- S. Woo, J. Park, J. Y. Lee, and I. S. Kweon, “CBAM: Convolutional block attention module,” in Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 2018, doi: 10.1007/978-3-030-01234-2_1.
- A. Vaswani et al., “Attention is all you need,” in Advances in Neural Information Processing Systems, 2017.
- T. B. Brown et al., “Language models are few-shot learners,” arXiv. 2020.
- A. Radrof and J. Wu, “language model and unsupervised multitask learning,” OpenAI, 2018.
- A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever, “Improving Language Understanding by Generative Pre-Training,” OpenAI, 2018.
- D. P. Kingma and M. Welling, “Auto-encoding variational bayes,” in 2nd International Conference on Learning Representations, ICLR 2014 - Conference Track Proceedings, 2014.
- I. J. Goodfellow et al., “Generative adversarial nets,” in Advances in Neural Information Processing Systems, 2014, doi: 10.3156/jsoft.29.5_177_2.
- M. Arjovsky, S. Chintala, and L. Bottou, “Wasserstein generative adversarial networks,” in 34th International Conference on Machine Learning, ICML 2017, 2017.
- D. P. Kingma and J. L. Ba, “Adam: A method for stochastic optimization,” in 3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings, 2015.
- Y. Huang, “Playing Atari with Deep Reinforcement Learning,” Deep Reinf. Learn. Fundam. Res. Appl., 2020.
- K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recognition,” in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2016, doi: 10.1109/CVPR.2016.90.
- Y. Gal and Z. Ghahramani, “Dropout as a Bayesian approximation: Representing model uncertainty in deep learning,” in 33rd International Conference on Machine Learning, ICML 2016, 2016.
- R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, and D. Batra, “Grad-cam: Why did you say that? visual explanations from deep networks via gradient-based localization,” Rev. do Hosp. das Cl??nicas, 2016.
- B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, and A. Torralba, “Learning Deep Features for Discriminative Localization,” in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2016, doi: 10.1109/CVPR.2016.319.
- N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov, “Dropout: A simple way to prevent neural networks from overfitting,” J. Mach. Learn. Res., 2014.
- C. Szegedy et al., “Going deeper with convolutions,” in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2015, doi: 10.1109/CVPR.2015.7298594.
- K. Simonyan and A. Zisserman, “Very deep convolutional networks for large-scale image recognition,” in 3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings, 2015.
- Y. Bengio, P. Lamblin, D. Popovici, and H. Larochelle, “Greedy layer-wise training of deep networks,” in Advances in Neural Information Processing Systems, 2007, doi: 10.7551/mitpress/7503.003.0024.
- G. E. Hinton, S. Osindero, and Y. W. Teh, “A fast learning algorithm for deep belief nets,” Neural Comput., 2006, doi: 10.1162/neco.2006.18.7.1527.
- P. Vincent, H. Larochelle, Y. Bengio, and P. A. Manzagol, “Extracting and composing robust features with denoising autoencoders,” in Proceedings of the 25th International Conference on Machine Learning, 2008, doi: 10.1145/1390156.1390294.
- X. Glorot and Y. Bengio, “Understanding the difficulty of training deep feedforward neural networks,” in Journal of Machine Learning Research, 2010.
- K. He, X. Zhang, S. Ren, and J. Sun, “Delving deep into rectifiers: Surpassing human-level performance on imagenet classification,” in Proceedings of the IEEE International Conference on Computer Vision, 2015, doi: 10.1109/ICCV.2015.123.
- A. Krizhevsky, I. Sutskever, and G. E. Hinton, “ImageNet classification with deep convolutional neural networks,” Commun. ACM, 2017, doi: 10.1145/3065386.
- I. Sutskever, J. Martens, and G. Hinton, “Generating text with recurrent neural networks,” in Proceedings of the 28th International Conference on Machine Learning, ICML 2011, 2011.
- D. Bahdanau, K. H. Cho, and Y. Bengio, “Neural machine translation by jointly learning to align and translate,” in 3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings, 2015.
- J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks for semantic segmentation,” in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2015, doi: 10.1109/CVPR.2015.7298965.
- V. Mnih et al., “Human-level control through deep reinforcement learning,” Nature, 2015, doi: 10.1038/nature14236.
- R. Girshick, “Fast R-CNN,” in Proceedings of the IEEE International Conference on Computer Vision, 2015, doi: 10.1109/ICCV.2015.169.
- B. WALLACH, “Faster RCNN,” A World Made Money, 2017.
- Walker, “mask-rcnn,” J. Chem. Inf. Model., 2005.
- J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, “You only look once: Unified, real-time object detection,” in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2016, doi: 10.1109/CVPR.2016.91.


## Remarkable research papers on Security
- P. Godefroid, N. Klarlund, and K. Sen, “DART: Directed Automated Random Testing,” in Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), 2005, doi: 10.1007/978-3-642-19237-1_4.
- D. Brumley, I. Jager, T. Avgerinos, and E. J. Schwartz, “BAP: A binary analysis platform,” in Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 2011, doi: 10.1007/978-3-642-22110-1_37.
- C. Lyu et al., “MOPT: Optimized mutation scheduling for fuzzers,” in Proceedings of the 28th USENIX Security Symposium, 2019.
- K. Sen, D. Marinov, and G. Agha, “CUTE: A concolic unit testing engine for C,” in ESEC/FSE’05 - Proceedings of the Joint 10th European Software Engineering Conference (ESEC) and 13th ACM SIGSOFT Symposium on the Foundations of Software Engineering (FSE-13), 2005.
- B. Dolan-Gavitt et al., “LAVA: Large-Scale Automated Vulnerability Addition,” in Proceedings - 2016 IEEE Symposium on Security and Privacy, SP 2016, 2016, doi: 10.1109/SP.2016.15.
- M. Böhme, V. T. Pham, and A. Roychoudhury, “Coverage-based Greybox Fuzzing as Markov chain,” in Proceedings of the ACM Conference on Computer and Communications Security, 2016, doi: 10.1145/2976749.2978428.
- I. Yun, S. Lee, M. Xu, Y. Jang, and T. Kim, “QSYM: A practical concolic execution engine tailored for hybrid fuzzing,” in Proceedings of the 27th USENIX Security Symposium, 2018.
- E. J. Schwartz, T. Avgerinos, and D. Brumley, “All you ever wanted to know about dynamic taint analysis and forward symbolic execution (but might have been afraid to ask),” in Proceedings - IEEE Symposium on Security and Privacy, 2010, doi: 10.1109/SP.2010.26.
- S. K. Cha, T. Avgerinos, A. Rebert, and D. Brumley, “Unleashing Mayhem on binary code,” in Proceedings of IEEE Symposium on Security and Privacy, 2012, doi: 10.1109/SP.2012.31.
- Y. Shoshitaishvili et al., “SOK: (State of) the Art of War: Offensive Techniques in Binary Analysis,” in Proceedings - 2016 IEEE Symposium on Security and Privacy, SP 2016, 2016, doi: 10.1109/SP.2016.17.
- C. Cadar, D. Dunbar, and D. Engler, “Klee: Unassisted and automatic generation of high-coverage tests for complex systems programs,” in Proceedings of the 8th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2008, 2019.
- V. Chipounov, V. Kuznetsov, and G. Candea, “S2E: A platform for in-vivo multi-path analysis of software systems,” in International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS, 2011, doi: 10.1145/1950365.1950396.
- H. Peng, Y. Shoshitaishvili, and M. Payer, “T-Fuzz: Fuzzing by Program Transformation,” in Proceedings - IEEE Symposium on Security and Privacy, 2018, doi: 10.1109/SP.2018.00056.
- C. Aschermann, S. Schumilo, T. Blazytko, R. Gawlik, and T. Holz, “REDQUEEN: Fuzzing with Input-to-State Correspondence,” in In 26th Annual Network and Distributed System Security Symposium, NDSS, 2019, doi: 10.14722/ndss.2019.23371.
- P. Chen and H. Chen, “Angora: Efficient Fuzzing by Principled Search,” in Proceedings - IEEE Symposium on Security and Privacy, 2018, doi: 10.1109/SP.2018.00046.
- S. Rawat, V. Jain, A. Kumar, L. Cojocar, C. Giuffrida, and H. Bos, “VUzzer: Application-aware Evolutionary Fuzzing,” 2017, doi: 10.14722/ndss.2017.23404.
- S. Kim et al., “Testing intermediate representations for binary analysis,” in ASE 2017 - Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering, 2017, doi: 10.1109/ASE.2017.8115648.
- N. Stephens et al., “Driller: Augmenting Fuzzing Through Selective Symbolic Execution,” 2017, doi: 10.14722/ndss.2016.23368.
